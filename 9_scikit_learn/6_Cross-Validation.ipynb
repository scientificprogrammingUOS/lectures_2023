{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60e91f6c-1b68-45b5-9cef-2f26c8533a5b",
   "metadata": {},
   "source": [
    "---\n",
    "# Evaluating Models\n",
    "---\n",
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c8dcc-2c7b-401d-9a02-ff38e30661fe",
   "metadata": {},
   "source": [
    "A common situation in machine learning is that your model classifies the training data perfectly, but it fizzles when it comes to unseen and new data. This phenomenon is called __overfitting__. Another problem could be that you model actually classifies an unrelated parameter, that randomly correlats with your target parameter. As an example your training data of cats and dogs could be accidentially cosists of only red cats and brown dogs. This can lead to a model that distinguishes beween red and brown instead of the characteristics of dogs and cats.   \n",
    "<br>\n",
    "There are several approaches to avoid these problems and measure the general performance of the model. One would be to split your dataset into a training and a testing or even a training, testing and validation set.   \n",
    "But these approaches do still lead to problems: Imagine for example accidentially splitting your training and testing set in a way that they are close to identical (except for the size). Then you cannot detect whether your model overfits your data.  \n",
    "And splitting into three datasets is not really possible when you have a small dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d5b13-80c4-4fce-9b2c-0f34f2b883d8",
   "metadata": {},
   "source": [
    "Cross-validation is a method with which you can test and train on the whole dataset. It is often used during the training of the model to test out different sets of hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f89cc6e-0f62-41a2-bbd5-a682508ee36f",
   "metadata": {},
   "source": [
    "### K-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c773dd4-c115-4c26-84dd-3ccfacc44f61",
   "metadata": {},
   "source": [
    "In k-fold cross-validataion you split the data into k-folds. After this:\n",
    "- the model is trained on _k - 1_ folds\n",
    "- the resulting model is tested with the remaining data fold \n",
    "This is repeated k-times in a loop. After this the performance is given as the average of all values computed in the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb3ab7-1125-47f4-9004-eae6a7430ac7",
   "metadata": {},
   "source": [
    "<img src=\"images/k-fold-cv.png\" width=\"700\" style=\"float: center;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e718ce-ffd4-4f68-918a-d98e3abca065",
   "metadata": {},
   "source": [
    "Image from [scikit learn](https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564f971-6357-4956-8b96-d40ab5dbc2fe",
   "metadata": {},
   "source": [
    "__Splitting the data:__  \n",
    "The first step that we have to do to use k-fold cross-validation is splitting the data into k-folds. For that we can use `train_test_split` from `sklearn.model_selection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf4be65-73b9-4942-9e07-7bf187eee813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first we take the iris data set:\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701d396c-f99a-4894-bce0-92ac9f64ea11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# then we use train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X is the data and y the target:\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# use test_train split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7fee84-a4d2-4214-b673-169a83692eeb",
   "metadata": {},
   "source": [
    "The splitted data can now be used to evaluate different hyperparameters in the dataset. To see how this looks like we will use again knn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91c796a7-f844-44e1-985a-ad5be7b5a27e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_score: 0.9800000000000001\n",
      "0.9066666666666667 accuracy with a standard deviation of 0.24248100345601728\n",
      "k-value: 6\n"
     ]
    }
   ],
   "source": [
    "# we need to import cross_val_score from model selection\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# we first select which k-values we want to test and create an empty array for the scores\n",
    "k_values = [i for i in range (1,15)]\n",
    "scores = np.zeros(15)\n",
    "\n",
    "# then we iterate through all the k-values\n",
    "for k in k_values:\n",
    "    # train the model\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    \n",
    "    # calculate the score with cross_val_score\n",
    "    score = cross_val_score(knn, X, y, cv = 5)\n",
    "    scores[k] = (np.mean(score))\n",
    "\n",
    "\n",
    "print(str(np.mean(scores)) + \" accuracy with a standard deviation of \" + str(np.std(scores)))    \n",
    "print('max_score:', np.max(scores))\n",
    "print('k-value:', np.argmax(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
